<div align="center">
  <h1>âœˆï¸ SkySafe â€” Flight & Weather Risk Analytics</h1>
  <p><b>Pipeline Big Data temps rÃ©el avec Machine Learning pour la surveillance du trafic aÃ©rien franÃ§ais.</b></p>
  <p>
    <img src="https://img.shields.io/badge/Apache_Airflow-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white" alt="Airflow" />
    <img src="https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white" alt="Spark" />
    <img src="https://img.shields.io/badge/Spark_MLlib-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white" alt="Spark MLlib" />
    <img src="https://img.shields.io/badge/Amazon_S3-569A31?style=for-the-badge&logo=amazon-s3&logoColor=white" alt="S3" />
    <img src="https://img.shields.io/badge/Elasticsearch-005571?style=for-the-badge&logo=elasticsearch&logoColor=white" alt="Elasticsearch" />
    <img src="https://img.shields.io/badge/Kibana-005571?style=for-the-badge&logo=kibana&logoColor=white" alt="Kibana" />
    <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker" />
    <img src="https://img.shields.io/badge/Scaleway_Serverless-4F0599?style=for-the-badge&logo=scaleway&logoColor=white" alt="Scaleway" />
  </p>

  <p>
    <a href="index.md"><strong>ğŸ“– Lire l'article complet (Blog Post)</strong></a>
  </p>
</div>

<br>

> **Projet rÃ©alisÃ© par [Tahiana Hajanirina Andriambahoaka](https://github.com/tahianahajanirina), [Mohamed Amar](https://github.com/mohamedbebay1-sys) et [Lounis Hamroun](https://github.com/lounishamroun)**
> dans le cadre du cours *DATA705 â€” BDD NoSQL* Ã  TÃ©lÃ©com Paris Â· FÃ©vrier 2026

---

## Ã€ propos du projet

**SkySafe** est une plateforme Big Data qui ingÃ¨re **toutes les minutes** les positions GPS des avions survolant la France, les croise avec la mÃ©tÃ©o locale, et produit :

1. Un **Score de Risque** (0â€“100) basÃ© sur les normes aÃ©ronautiques FAA (orages, vent, visibilitÃ©, altitudeâ€¦)
2. Une **classification automatique** de la phase de vol (DÃ©collage / CroisiÃ¨re / MontÃ©e-Descente) via **K-Means** (Spark MLlib)
3. Une **dÃ©tection d'anomalies** comportementales (vols dont la cinÃ©matique s'Ã©carte de leur groupe)

Le tout est exposÃ© sur un **dashboard Kibana interactif** avec carte, graphiques et filtres â€” rafraÃ®chi toutes les minutes.

![Dashboard Kibana SkySafe](./src/dashboard/kibana_dashboard_example.png)

---

## FonctionnalitÃ©s clÃ©s

| FonctionnalitÃ© | Description |
|---|---|
| **Machine Learning (K-Means)** | Classification non-supervisÃ©e des phases de vol via PySpark MLlib. MÃ©canisme hybride : K-Means quand le trafic est hÃ©tÃ©rogÃ¨ne, **fallback automatique sur des rÃ¨gles mÃ©tier aÃ©ronautiques** quand les donnÃ©es sont homogÃ¨nes (ex. la nuit). |
| **DÃ©tection d'anomalies** | Distance euclidienne au centroÃ¯de du cluster. Seuil dynamique Î¼ + 2Ïƒ â†’ identifie les ~5 % de vols les plus atypiques. |
| **Score de risque FAA** | Score composite 0â€“100 croisant mÃ©tÃ©o + altitude + cinÃ©matique, basÃ© sur les recommandations officielles de la FAA. |
| **Cloud Serverless** | Proxy Lambda (Scaleway) contournant le blocage d'IP AWS par OpenSky. |
| **Data Lake S3** | Architecture Medallion 4 couches (`raw` â†’ `formatted` â†’ `enriched` â†’ `usage`) sur Amazon S3. |
| **Auto-Provisioning Kibana** | Un DAG Airflow dÃ©diÃ© importe automatiquement le dashboard au premier lancement (zÃ©ro config manuelle). |
| **Full Docker** | 6 services conteneurisÃ©s, lancement en une seule commande. |

---

## Architecture du Pipeline

Le pipeline suit le modÃ¨le `Raw â†’ Formatted â†’ Enriched â†’ Usage`, orchestrÃ© par **Apache Airflow** avec une exÃ©cution toutes les minutes :

```text
  extract_flights â”€â”€â–º format_flights_spark â”€â”€â”
                                              â”œâ”€â”€â–º combine_data_spark â”€â”€â–º index_to_elastic
  extract_weather â”€â”€â–º format_weather_spark â”€â”€â”˜
```

Les deux branches d'extraction s'exÃ©cutent **en parallÃ¨le**. La jointure spatiale + ML ne dÃ©marre qu'une fois les deux formatages terminÃ©s avec succÃ¨s.

### DÃ©tail des 4 Ã©tapes

| Ã‰tape | Couche S3 | Description |
|---|---|---|
| **1. Extract** | `raw/` | Ingestion JSON depuis l'API **OpenSky** (via proxy Serverless Scaleway) et l'API **Open-Meteo** (6 stations mÃ©tÃ©o franÃ§aises). |
| **2. Format** | `formatted/` | Nettoyage PySpark : typage, filtrage des vols sans GPS, normalisation des horodatages en **UTC**, conversion en **Parquet**. |
| **3. Combine & ML** | `enriched/` | **Jointure spatiale** (formule de Haversine) vols Ã— station mÃ©tÃ©o la plus proche. Calcul du **Score de Risque** (0â€“100). EntraÃ®nement **K-Means** pour classifier les phases de vol, avec **fallback automatique** sur des rÃ¨gles mÃ©tier quand le trafic est homogÃ¨ne. **DÃ©tection d'anomalies** par distance euclidienne au centroÃ¯de (seuil Î¼ + 2Ïƒ). |
| **4. Index** | `usage/` | SÃ©lection des colonnes dashboard, fusion lat/lon en `geo_point`, indexation **bulk** dans Elasticsearch (upsert par ICAO24 â†’ pas de doublons). |

![Architecture du pipeline SkySafe](utils/architecture.png)

---

## Stack technique

| Composant | Technologie | RÃ´le |
|---|---|---|
| Orchestration | **Apache Airflow 2.7** | Planification du pipeline toutes les minutes (`* * * * *`), gestion des dÃ©pendances et retry automatique |
| Traitement | **Apache Spark (PySpark)** | Nettoyage, jointure spatiale (Haversine), score de risque â€” 100% expressions natives Spark (pas de UDF Python) |
| Machine Learning | **Spark MLlib** | K-Means, StandardScaler, VectorAssembler, Pipeline â€” classification de phases + dÃ©tection d'anomalies |
| Stockage | **Amazon S3** | Data Lake cloud, architecture Medallion 4 couches, partitionnement `date=YYYY-MM-DD/hour=HH` |
| Indexation | **Elasticsearch 8.10** | Indexation temps rÃ©el avec mapping typÃ© (`geo_point`, `keyword`, `float`, `boolean`, `date`) |
| Visualisation | **Kibana 8.10** | Dashboard interactif : carte, histogrammes, pie chart des phases, tableau filtrable |
| Serverless | **Scaleway Functions** | Proxy Lambda contournant le ban IP d'OpenSky sur AWS |
| Infrastructure | **Docker & Docker Compose** | 6 conteneurs, healthchecks, dÃ©marrage en une commande |
| Base Airflow | **PostgreSQL 13** | MÃ©tadonnÃ©es et Ã©tat des DAGs Airflow |

---

## Sources de donnÃ©es

### OpenSky Network (vols en temps rÃ©el)

L'API [OpenSky Network](https://openskynetwork.github.io/opensky-api/rest.html) fournit la position de chaque avion Ã©quipÃ© d'un transpondeur ADS-B au-dessus de la France : ICAO24, callsign, latitude, longitude, altitude, vitesse, cap, taux vertical, pays d'origine.

> âš ï¸ OpenSky bloque les IPs des hyperscalers (AWS, GCPâ€¦). Notre solution : un **proxy Serverless Scaleway** qui interroge l'API depuis une IP non bloquÃ©e.

### Open-Meteo (mÃ©tÃ©o locale)

L'API [Open-Meteo](https://open-meteo.com/en/docs) fournit les conditions mÃ©tÃ©o actuelles pour **6 stations** couvrant la France : Paris CDG, Toulouse, Lyon, Marseille, Nantes, Lille. Variables : tempÃ©rature, vent, rafales, pluie, visibilitÃ©, couverture nuageuse, code mÃ©tÃ©o (dont orages).

Chaque avion est associÃ© Ã  la station la plus proche via la **formule de Haversine** (distance sur la sphÃ¨re terrestre).

---

## Machine Learning â€” En bref

### Classification des phases de vol (K-Means)

Un modÃ¨le **K-Means** (k=3) est entraÃ®nÃ© Ã  chaque cycle sur les vecteurs normalisÃ©s `(velocity, baro_altitude, vertical_rate)`. Les 3 clusters correspondent Ã  :

| Cluster | Phase de vol |
|---|---|
| Altitude basse, vitesse faible | **Takeoff / Landing** |
| Altitude variable, fort taux vertical | **Climb / Descent** |
| Haute altitude, vitesse Ã©levÃ©e, taux ~0 | **Cruise** |

**MÃ©canisme hybride :** si les centroÃ¯des sont trop proches (distance max < 1.0 en espace normalisÃ©), le K-Means est jugÃ© non significatif et le pipeline bascule automatiquement sur des **rÃ¨gles mÃ©tier aÃ©ronautiques** (seuils d'altitude, vitesse, taux vertical).

### DÃ©tection d'anomalies

La **distance euclidienne** entre chaque avion et le centroÃ¯de de son cluster constitue l'`anomaly_score`. Un vol est marquÃ© anomalie si son score dÃ©passe le seuil dynamique **Î¼ + 2Ïƒ** (~5 % des vols les plus atypiques).

---

## Dashboard Kibana

Le dashboard est importÃ© **automatiquement** au premier lancement via un DAG dÃ©diÃ© (`setup_kibana_once`) qui attend l'arrivÃ©e des donnÃ©es dans Elasticsearch.

**Visualisations disponibles :**

- **Carte interactive** â€” Position de chaque avion avec code couleur selon le niveau de risque (vert / orange / rouge)
- **RÃ©partition des phases de vol** â€” Diagramme circulaire : Cruise, Takeoff/Landing, Climb/Descent
- **Distribution des scores** â€” Histogrammes du risk score et de l'anomaly score
- **Tableau dÃ©taillÃ©** â€” Callsign, pays, altitude, vitesse, score de risque, phase de vol, statut d'anomalie â€” filtrable et triable
- **Mise en Ã©vidence des anomalies** â€” Les vols atypiques dÃ©tectÃ©s par le ML sont mis en avant

---

## Infrastructure Docker

L'ensemble du projet est conteneurisÃ© via **Docker Compose** (6 services) :

| Service | Image | Port | RÃ´le |
|---|---|---|---|
| `postgres` | `postgres:13` | â€” | Base de donnÃ©es interne d'Airflow |
| `airflow-init` | Custom (Airflow 2.7.1 + Java 11 + JARs Hadoop S3) | â€” | Migration BDD + crÃ©ation utilisateur admin |
| `airflow-webserver` | Custom | `8090` | Interface web Airflow |
| `airflow-scheduler` | Custom | â€” | Planificateur (dÃ©clenche le DAG toutes les minutes) |
| `elasticsearch` | `elasticsearch:8.10.2` | `9200` | Moteur de recherche et base de donnÃ©es finale |
| `kibana` | `kibana:8.10.2` | `5601` | Dashboard de visualisation |

**Points notables :**
- **Java 11** est installÃ© dans le Dockerfile pour PySpark
- Les **JARs Hadoop AWS** (`hadoop-aws-3.3.4` + `aws-java-sdk-bundle-1.12.262`) permettent Ã  Spark de lire/Ã©crire sur S3 via le protocole `s3a://`
- Les volumes Docker montent `dags/`, `src/` et `data/` en temps rÃ©el â€” toute modification du code est appliquÃ©e sans rebuild
- Des **healthchecks** et `depends_on` orchestrent l'ordre de dÃ©marrage des services

---

## SÃ©curitÃ©

**Aucun secret n'est exposÃ© dans le code source.** Toutes les donnÃ©es sensibles sont externalisÃ©es dans un fichier `.env` (exclu du dÃ©pÃ´t via `.gitignore`) :

| Variable | Description |
|---|---|
| `POSTGRES_USER` / `POSTGRES_PASSWORD` | Credentials PostgreSQL |
| `AIRFLOW__CORE__FERNET_KEY` | ClÃ© de chiffrement des connexions Airflow |
| `AIRFLOW__CORE__SECRET_KEY` / `AIRFLOW__WEBSERVER__SECRET_KEY` | ClÃ©s JWT partagÃ©es webserver/scheduler |
| `AIRFLOW_ADMIN_USER` / `AIRFLOW_ADMIN_PASSWORD` | Identifiants de l'utilisateur Airflow |
| `AWS_ACCESS_KEY_ID` / `AWS_SECRET_ACCESS_KEY` | Credentials AWS pour l'accÃ¨s S3 |
| `SKY_NETWORK_CLIENT_ID` / `SKY_NETWORK_CLIENT_SECRET` | Credentials OAuth2 OpenSky Network |

---

## Guide de dÃ©marrage

### 1. PrÃ©requis

- [Docker](https://www.docker.com/) et [Docker Compose](https://docs.docker.com/compose/) installÃ©s
- Au moins **6 Go de RAM** allouÃ©s Ã  Docker (Spark + Elasticsearch)
- Un compte AWS avec un bucket S3 configurÃ©
- Un compte [OpenSky Network](https://opensky-network.org/) (gratuit)

### 2. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/tahianahajanirina/skysafe-datalake.git
cd skysafe-datalake
```

### 3. Configurer les secrets (`.env`)

CrÃ©ez un fichier `.env` Ã  la racine du projet avec vos credentials :

```env
# === PostgreSQL ===
POSTGRES_USER=airflow
POSTGRES_PASSWORD=changeme
POSTGRES_DB=airflow

# === Airflow ===
# GÃ©nÃ©rer une Fernet key : python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW__CORE__FERNET_KEY=CHANGE_ME_GENERATE_A_REAL_FERNET_KEY
AIRFLOW__CORE__SECRET_KEY=CHANGE_ME_USE_A_LONG_RANDOM_STRING
AIRFLOW__WEBSERVER__SECRET_KEY=CHANGE_ME_USE_A_LONG_RANDOM_STRING
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_PASSWORD=CHANGE_ME

# === OpenSky Network ===
SKY_NETWORK_BASE_URL=https://opensky-network.org/api
SKY_NETWORK_TOKEN_URL=https://auth.opensky-network.org/auth/realms/opensky-network/protocol/openid-connect/token
SKY_NETWORK_CLIENT_ID=CHANGE_ME
SKY_NETWORK_CLIENT_SECRET=CHANGE_ME

# === Amazon S3 ===
AWS_ACCESS_KEY_ID=CHANGE_ME
AWS_SECRET_ACCESS_KEY=CHANGE_ME
AWS_DEFAULT_REGION=eu-north-1
```

### 4. Lancer le projet

```bash
MY_UID=$(id -u) docker-compose up -d --build
```

### 5. AccÃ©der aux interfaces

| Interface | URL |
|---|---|
| **Airflow** (UI web) | [http://localhost:8090](http://localhost:8090) |
| **Kibana** (Dashboard) | [http://localhost:5601](http://localhost:5601) |
| **Elasticsearch** (API) | [http://localhost:9200](http://localhost:9200) |

Le DAG `sky_safe_pipeline` dÃ©marre automatiquement et s'exÃ©cute toutes les minutes. Le dashboard Kibana est importÃ© automatiquement dÃ¨s que les premiÃ¨res donnÃ©es arrivent dans Elasticsearch.

![DAGs Airflow du projet SkySafe](utils/dags_airflow.png)

### 6. ArrÃªter le projet

```bash
docker-compose down
```

Pour supprimer les donnÃ©es Elasticsearch persistantes :

```bash
docker-compose down -v
```

---

## ğŸ“ Structure du projet

![Arborescence du projet SkySafe](utils/arborescence.png)

<details>
<summary>ğŸ“ DÃ©tail des fichiers principaux</summary>

| Fichier | RÃ´le |
|---|---|
| `dags/sky_safe_dag.py` | DAG principal â€” pipeline exÃ©cutÃ© toutes les minutes |
| `dags/setup_kibana_dag.py` | DAG one-shot â€” import automatique du dashboard Kibana |
| `src/helpers.py` | Utilitaires partagÃ©s (S3, Spark, logging, config) |
| `src/extract_flights.py` | Extraction des vols (OpenSky via Lambda Scaleway) |
| `src/extract_weather.py` | Extraction mÃ©tÃ©o (Open-Meteo, 6 stations) |
| `src/format_flights.py` | Nettoyage + normalisation UTC des vols (Spark â†’ Parquet) |
| `src/format_weather.py` | Nettoyage + normalisation UTC de la mÃ©tÃ©o (Spark â†’ Parquet) |
| `src/combine_spark.py` | Jointure Haversine + Score de Risque + K-Means + Anomalies |
| `src/index_elastic.py` | Couche Usage + Bulk indexation Elasticsearch |
| `src/setup_kibana.py` | Import du dashboard Kibana via API Saved Objects |
| `src/serverless_function_call.py` | Client d'appel vers la Lambda Scaleway |
| `src/dashboard/kibana_dashboard_config.ndjson` | Configuration exportÃ©e du dashboard Kibana |
| `docker-compose.yml` | Orchestration des 6 conteneurs |
| `Dockerfile` | Image custom Airflow + Java 11 + JARs Hadoop S3 |
| `index.md` | Article / Blog Post dÃ©taillÃ© du projet |

</details>

---

## Tests

Le projet inclut **42 tests** couvrant les fonctions critiques du pipeline :

| Fichier | Ce qui est testÃ© |
|---|---|
| `test_format_flights.py` | Helpers pure-Python : `_safe_get`, `_to_float`, `_clean_callsign` |
| `test_haversine.py` | Expression Spark Haversine (distances rÃ©elles, symÃ©trie) |
| `test_risk_score.py` | Score de risque composite + catÃ©gorisation LOW / MEDIUM / HIGH |
| `test_index_elastic.py` | Transformation `_row_to_es_doc` + mapping Elasticsearch |

```bash
# En local (les tests Spark sont auto-skippÃ©s si Java n'est pas installÃ©)
pip install -r requirements.txt pytest
pytest

# Via Docker (tous les tests passent, Java inclus dans l'image)
docker compose run --rm airflow-worker pytest
```

---

## Documentation complÃ¨te

Pour une description dÃ©taillÃ©e du projet â€” choix techniques, obstacles rencontrÃ©s, explication du Machine Learning, et leÃ§ons apprises â€” consultez notre article complet :

ğŸ‘‰ **[Lire le Blog Post](https://tahianahajanirina.github.io/skysafe-datalake/)**

---

## Auteurs

| | Nom | GitHub |
|---|---|---|
| ğŸ‘¨â€ğŸ’» | **Tahiana Hajanirina Andriambahoaka** | [@tahianahajanirina](https://github.com/tahianahajanirina) |
| ğŸ‘¨â€ğŸ’» | **Mohamed Amar** | [@mohamedbebay1-sys](https://github.com/mohamedbebay1-sys) |
| ğŸ‘¨â€ğŸ’» | **Lounis Hamroun** | [@lounishamroun](https://github.com/lounishamroun) |

---

<div align="center">
  <sub>Projet SkySafe â€” DATA705 BDD NoSQL â€” TÃ©lÃ©com Paris â€” FÃ©vrier 2026</sub>
</div>